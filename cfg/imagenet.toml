title = "Config file for running model with Imagenet"


[misc]
    seed = 1337                     # Set seed for reproducibility
    mode = 'train'                  # Mode: 'train' or 'eval'


[hardware]
    device = 'gpu'                  # Select the device to be used. Supported: 'gpu', 'cpu'
    num_gpu = 1                     # Count of GPUs to use. Supported: 1. Ignored if device is 'cpu'
    allow_memory_growth = true      # If true, then allocates memory on need basis. Ignored if device is 'cpu'
    force_eager = true  # Force tf.function() to run eagerly. Will slow down processing, but enable putting breakpoints for debugging


[dataset]
    dataset = 'imagenet'             # Dataset to use. Supported: 'cifar10', 'imagenet'


[imagenet]
# ----- Only used if dataset is 'imagenet' -----
    # Path to text file containing 1,281,167 image paths
    train_img_paths = '/hd1/datasets/imagenet/input/input_list_train.txt'
    # Path to text file containing 50,000 image paths
    val_img_paths = '/hd1/datasets/imagenet/input_list_val.txt'
    # Path to text file containing 50,000 image class labels. Values are in range 1 to 1000
    val_labels = '/hd1/datasets/imagenet/ILSVRC2012_devkit_t12/data/ILSVRC2012_validation_ground_truth.txt'
    # path to json file containing a dictionary mapping WNID (e.g. 'n01440764') to class label (int in range 1 to 1000)
    # This is needed to get class labels of training images from their paths
    wnid_to_ilsvrc2012_id_path = '/hd1/datasets/imagenet/wnid_to_ilsvrc2012_id.json'

    num_classes = 1000

[directories]
    # Paths can either be absolute or relative to repository directory
    dir_model = 'models'                # Directory to store final trained models
    dir_log = 'logs'                    # Directory to store log files
    dir_tb_home = 'logs/tensorboard'    # Directory to store tensorboard logs
    dir_ckpt = 'checkpoints'            # Directory to store training checkpoints


# Training phase parameters
# ----- Only used if misc.mode is 'train' -----
[train]
    batch_size = 64
    num_epochs = 2              # Count epochs to further train for
    enable_summary = false       # Enable/disable tensorboard summary for training

    enable_train_chekpoints = true  # Whether to enable storing checkpoints with n/w parameters while training
    # Checkpoint parameters below are only used if enable_checkpoints is true
    checkpoint_interval = 1  # Epoch interval after which checkpoint must be saved
    keep_n_checkpoints = 1  # Count of checkpoints to keep

    enable_save_best_model = true  # Whether to save model with best weights
    best_model_criteria = 'val_loss'  # Supported 'train_loss', 'val_loss'

# Validation phase parameters
# ----- Only used if misc.mode is 'train' -----
[validation]
    enable = true              # Enables or disables validation set evaluation during training

    # ----- parameters below are ignored if enable is false -----

    batch_size = -1             # If -1, then uses the same batch_size as in training
    validation_interval = 10    # After how many epochs should validation set be evaluated


# Eval phase parameters
# ----- Only used if misc.mode is 'eval' -------
[eval]
    portion = 'test'            # Evaluates the model's performance on specified portion
                                # Portion of entire dataset to use. Supported: 'train', 'val', 'test'
    batch_size = 64



[model]
    batch_norm_decay = 0.9
    weight_decay = 0.0
    data_format = 'channels_last'  # Supported values: 'channels_first', 'channels_last'

[preprocessing]
    enable_augmentation = true
