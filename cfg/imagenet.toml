title = "Config file for running model with Imagenet"


[misc]
    seed = 1337                     # Set seed for reproducibility
    mode = 'train'                  # Mode: 'train' or 'eval'


[hardware]
    device = 'gpu'                  # Select the device to be used. Supported: 'gpu', 'cpu'
    num_gpu = 1                     # Count of GPUs to use. Supported: 1. Ignored if device is 'cpu'
    allow_memory_growth = true      # If true, then allocates memory on need basis. Ignored if device is 'cpu'
    force_eager = false  # Force tf.function() to run eagerly. Will slow down processing, but enable putting breakpoints for debugging


[dataset]
    dataset = 'imagenet'             # Dataset to use. Supported: 'cifar10', 'imagenet'


[imagenet]
# ----- Only used if dataset is 'imagenet' -----
    # Path to text file containing 1,281,167 image paths
    train_img_paths = '/home/govind/work/imagenet/input_list_train.txt'

    # Path to directory containing 50,000 validation images
    val_img_base_path = '/home/govind/work/imagenet/val'
    # Path to CSV file: LOC_val_solution.csv
    val_labels_csv = '/home/govind/work/imagenet/LOC_val_solution.csv'
    # path to json file containing a dictionary mapping WNID (e.g. 'n01440764') to class label (int in range 1 to 1000)
    # This is needed to get class labels of training images from their paths
    wnid_to_ilsvrc2012_id_path = '/home/govind/work/imagenet/wnid_to_ilsvrc2012_id.json'

    num_classes = 1000

[directories]
    # Paths can either be absolute or relative to repository directory
    dir_model = 'models'                # Directory to store final trained models
    dir_log = 'logs'                    # Directory to store log files
    dir_tb_home = 'logs/tensorboard'    # Directory to store tensorboard logs
    dir_ckpt = 'checkpoints'            # Directory to store training checkpoints


# Training phase parameters
# ----- Only used if misc.mode is 'train' -----
[train]
    batch_size = 32
    num_epochs = 2              # Count epochs to further train for
    enable_summary = false       # Enable/disable tensorboard summary for training

    enable_chekpoints = true  # Whether to enable storing checkpoints with n/w parameters while training
    # Checkpoint parameters below are only used if enable_checkpoints is true
    checkpoint_interval = 1  # Epoch interval after which checkpoint must be saved
    keep_n_checkpoints = 1  # Count of checkpoints to keep
    # Searches for checkpoints in directory specified by directories.dir_ckpt
    # Specify the ckeckpoint from which to save the model
    #   'none': Do not load from a stored checkpoint. This allows storing new ckpts while also starting from scratch
    #   'latest': Latest checkpoint
    #   <int>: checkpoint integer id
    checkpoint_id = 'latest'

    enable_intermittent_sleep = true
    sleep_interval = 1800  # In seconds. Interval after which to sleep
    sleep_duration = 300  # In seconds. Duration for which to sleep

# Validation phase parameters
# ----- Only used if misc.mode is 'train' -----
[validation]
    enable = true              # Enables or disables validation set evaluation during training

    # ----- parameters below are ignored if enable is false -----

    batch_size = -1             # If -1, then uses the same batch_size as in training
    validation_interval = 10    # After how many epochs should validation set be evaluated


# Eval phase parameters
# ----- Only used if misc.mode is 'eval' -------
[eval]
    portion = 'val'            # Evaluates the model's performance on specified portion
                                # Portion of entire dataset to use. Supported: 'train', 'val', 'test'
    batch_size = 64

    # Supported value:
    #   'checkpoint': Load from checkpoint as specified by eval.checkpoint_id
    #   'saved': Load model from a saved model in directory directories.dir_model
    load_from = 'saved'  # Supported: 'checkpoint', 'saved'

    # If eval.load_from is 'checkpoint', then this is used to specify which checkpoint to load from
    # Searches for checkpoints in directory specified by directories.dir_ckpt
    #   'latest': Latest checkpoint
    #   <int>: checkpoint integer id
    checkpoint_id = 'latest'


# Config parameters for the scripts/save_model.py script
[model_saver]
    # Searches for checkpoints in directory specified by directories.dir_ckpt
    # Specify the ckeckpoint from which to save the model
    #   'none': Do not load from a stored checkpoint. We should get about 0.1% top-1 accuracy with Imagenet with this
    #   'latest': Latest checkpoint
    #   <int>: checkpoint integer id
    checkpoint_id = 'latest'


[model]
    batch_norm_decay = 0.9
    weight_decay = 0.0
    data_format = 'channels_last'  # Supported values: 'channels_first', 'channels_last'

[preprocessing]
    enable_augmentation = true
